{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laribar/bitcoinprediction/blob/main/modelo_yfinance_geral.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sO6bH78d0lio",
        "outputId": "0ae4f9a6-0bb1-4b96-8cb0-cde879e1487e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stock: ADBE | Intervalo: 1d\n",
            "Last price: 389.61\n",
            "Predictions: [434.79028123 434.79028123 434.79028123 434.79028123 434.79028123]\n",
            "Alert: üöÄ Compra sugerida\n",
            "Justificativa: A m√©dia das previs√µes futuras (434.79) √© 2% maior que o pre√ßo atual (389.61). Isso indica uma tend√™ncia de alta.\n",
            "\n",
            "Probabilidades de Atingir o Pre√ßo Alvo:\n",
            "Previs√£o: 434.79 | Probabilidade: 100.00% | Dias: 1\n",
            "Previs√£o: 434.79 | Probabilidade: 99.98% | Dias: 2\n",
            "Previs√£o: 434.79 | Probabilidade: 99.78% | Dias: 3\n",
            "Previs√£o: 434.79 | Probabilidade: 99.32% | Dias: 4\n",
            "Previs√£o: 434.79 | Probabilidade: 98.64% | Dias: 5\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stock: AMD | Intervalo: 1d\n",
            "Last price: 107.14\n",
            "Predictions: [108.47992994 108.47992994 108.47992994 108.47992994 108.47992994]\n",
            "Alert: üîç Acompanhar\n",
            "Justificativa: A m√©dia das previs√µes futuras (108.48) est√° dentro de 2% do pre√ßo atual (107.14). Isso sugere que o mercado est√° est√°vel no momento.\n",
            "\n",
            "Probabilidades de Atingir o Pre√ßo Alvo:\n",
            "Previs√£o: 108.48 | Probabilidade: 66.30% | Dias: 1\n",
            "Previs√£o: 108.48 | Probabilidade: 61.69% | Dias: 2\n",
            "Previs√£o: 108.48 | Probabilidade: 59.59% | Dias: 3\n",
            "Previs√£o: 108.48 | Probabilidade: 58.33% | Dias: 4\n",
            "Previs√£o: 108.48 | Probabilidade: 57.46% | Dias: 5\n",
            "--------------------------------------------------------------------------------\n",
            "Stock: ABNB | Intervalo: 1d\n",
            "Last price: 126.15\n",
            "Predictions: [120.68930519 120.68930519 120.68930519 120.68930519 120.68930519]\n",
            "Alert: ‚ö†Ô∏è Venda sugerida\n",
            "Justificativa: A m√©dia das previs√µes futuras (120.69) √© 2% menor que o pre√ßo atual (126.15). Isso indica uma tend√™ncia de baixa.\n",
            "\n",
            "Probabilidades de Atingir o Pre√ßo Alvo:\n",
            "Previs√£o: 120.69 | Probabilidade: 2.97% | Dias: 1\n",
            "Previs√£o: 120.69 | Probabilidade: 9.13% | Dias: 2\n",
            "Previs√£o: 120.69 | Probabilidade: 13.82% | Dias: 3\n",
            "Previs√£o: 120.69 | Probabilidade: 17.29% | Dias: 4\n",
            "Previs√£o: 120.69 | Probabilidade: 19.96% | Dias: 5\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import logging\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Configura√ß√£o de logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# Fun√ß√£o para baixar dados e calcular m√©tricas t√©cnicas\n",
        "def baixar_dados(acao, intervalo=\"1d\", periodo=\"2y\"):\n",
        "    try:\n",
        "        # Baixar dados da a√ß√£o\n",
        "        df = yf.download(acao, period=periodo, interval=intervalo, progress=False, auto_adjust=True)\n",
        "        if df.empty or df.isnull().values.any():\n",
        "            logging.error(f\"Erro: Dados faltantes ou inv√°lidos para {acao}.\")\n",
        "            return None\n",
        "\n",
        "        preco_coluna = \"Close\"\n",
        "\n",
        "        if preco_coluna not in df.columns:\n",
        "            logging.error(f\"Erro ao processar {acao}: Nenhuma coluna de fechamento encontrada nos dados.\")\n",
        "            return None\n",
        "\n",
        "        # Remove NaNs\n",
        "        df.dropna(inplace=True)\n",
        "\n",
        "        # M√©dias M√≥veis\n",
        "        df[\"SMA_9\"] = df[preco_coluna].rolling(window=9).mean().shift(1)\n",
        "        df[\"SMA_21\"] = df[preco_coluna].rolling(window=21).mean().shift(1)\n",
        "        df[\"EMA_50\"] = df[preco_coluna].ewm(span=50, adjust=False).mean().shift(1)\n",
        "\n",
        "        # Bandas de Bollinger\n",
        "        df[\"STD\"] = df[preco_coluna].rolling(window=20).std().shift(1)\n",
        "        df[\"Upper_Band\"] = df[\"SMA_21\"] + (df[\"STD\"] * 2)\n",
        "        df[\"Lower_Band\"] = df[\"SMA_21\"] - (df[\"STD\"] * 2)\n",
        "\n",
        "        # RSI (√çndice de For√ßa Relativa)\n",
        "        delta = df[preco_coluna].diff()\n",
        "        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
        "        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
        "        rs = gain / loss\n",
        "        df[\"RSI\"] = 100 - (100 / (1 + rs)).shift(1)\n",
        "\n",
        "        # MACD (Moving Average Convergence Divergence)\n",
        "        df[\"EMA_12\"] = df[preco_coluna].ewm(span=12, adjust=False).mean()\n",
        "        df[\"EMA_26\"] = df[preco_coluna].ewm(span=26, adjust=False).mean()\n",
        "        df[\"MACD\"] = df[\"EMA_12\"] - df[\"EMA_26\"]\n",
        "        df[\"MACD_Signal\"] = df[\"MACD\"].ewm(span=9, adjust=False).mean()\n",
        "        df[\"MACD_Histogram\"] = df[\"MACD\"] - df[\"MACD_Signal\"]\n",
        "\n",
        "        # ADX (Average Directional Index)\n",
        "        df[\"TR\"] = np.maximum(\n",
        "            df[\"High\"] - df[\"Low\"],\n",
        "            np.maximum(abs(df[\"High\"] - df[preco_coluna].shift(1)), abs(df[\"Low\"] - df[preco_coluna].shift(1)))\n",
        "        )\n",
        "        df[\"ATR\"] = df[\"TR\"].rolling(window=14).mean()\n",
        "        df[\"Plus_DM\"] = np.where(\n",
        "            (df[\"High\"] - df[\"High\"].shift(1)) > (df[\"Low\"].shift(1) - df[\"Low\"]),\n",
        "            np.maximum(df[\"High\"] - df[\"High\"].shift(1), 0),\n",
        "            0\n",
        "        )\n",
        "        df[\"Minus_DM\"] = np.where(\n",
        "            (df[\"Low\"].shift(1) - df[\"Low\"]) > (df[\"High\"] - df[\"High\"].shift(1)),\n",
        "            np.maximum(df[\"Low\"].shift(1) - df[\"Low\"], 0),\n",
        "            0\n",
        "        )\n",
        "        df[\"Plus_DI\"] = (df[\"Plus_DM\"].rolling(window=14).mean() / df[\"ATR\"]) * 100\n",
        "        df[\"Minus_DI\"] = (df[\"Minus_DM\"].rolling(window=14).mean() / df[\"ATR\"]) * 100\n",
        "        df[\"DX\"] = (abs(df[\"Plus_DI\"] - df[\"Minus_DI\"]) / (df[\"Plus_DI\"] + df[\"Minus_DI\"])) * 100\n",
        "        df[\"ADX\"] = df[\"DX\"].rolling(window=14).mean().shift(1)\n",
        "\n",
        "        # Estoc√°stico (%K e %D)\n",
        "        df[\"%K\"] = ((df[preco_coluna] - df[\"Low\"].rolling(window=14).min()) /\n",
        "                   (df[\"High\"].rolling(window=14).max() - df[\"Low\"].rolling(window=14).min())) * 100\n",
        "        df[\"%D\"] = df[\"%K\"].rolling(window=3).mean().shift(1)\n",
        "\n",
        "        # ATR (Average True Range)\n",
        "        df[\"ATR\"] = df[\"TR\"].rolling(window=14).mean().shift(1)\n",
        "\n",
        "        # VIX (√çndice de Volatilidade)\n",
        "        vix = yf.download(\"^VIX\", period=periodo, interval=intervalo, progress=False)\n",
        "        df[\"VIX\"] = vix[\"Close\"].shift(1)\n",
        "\n",
        "        # Remove colunas auxiliares que n√£o ser√£o usadas no modelo\n",
        "        df = df.drop(columns=[\"STD\", \"TR\", \"Plus_DM\", \"Minus_DM\", \"DX\", \"EMA_12\", \"EMA_26\"])\n",
        "\n",
        "        return df\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Erro ao baixar dados para {acao}: {e}\", exc_info=True)\n",
        "        return None\n",
        "\n",
        "# Fun√ß√£o para calcular a probabilidade de atingir o pre√ßo alvo\n",
        "def calcular_probabilidade(preco_atual, preco_alvo, volatilidade, dias):\n",
        "    \"\"\"\n",
        "    Calcula a probabilidade de atingir o pre√ßo alvo com base na volatilidade e no horizonte de tempo.\n",
        "    \"\"\"\n",
        "    # Garantir que preco_atual e volatilidade sejam valores escalares\n",
        "    if isinstance(preco_atual, pd.Series):\n",
        "        preco_atual = preco_atual.item()  # Converte para valor escalar\n",
        "    if isinstance(volatilidade, pd.Series):\n",
        "        volatilidade = volatilidade.item()  # Converte para valor escalar\n",
        "\n",
        "    if preco_atual == 0 or volatilidade == 0:\n",
        "        return 0.0\n",
        "\n",
        "    T = dias / 252  # Converter dias para anos (252 dias √∫teis no ano)\n",
        "    d1 = (np.log(preco_alvo / preco_atual)) / (volatilidade * np.sqrt(T))\n",
        "    probabilidade = norm.cdf(d1)\n",
        "    return probabilidade\n",
        "\n",
        "# Fun√ß√£o para treinar o modelo e prever pre√ßos futuros com probabilidades\n",
        "def prever_precos_com_probabilidade(df, acao, intervalo):\n",
        "    try:\n",
        "        # Definir target como o pre√ßo do dia seguinte\n",
        "        df[\"Target\"] = df[\"Close\"].shift(-1)\n",
        "        df.dropna(inplace=True)  # Remove a √∫ltima linha com target NaN\n",
        "\n",
        "        # Selecionar features e target\n",
        "        features = [\n",
        "            'SMA_9', 'SMA_21', 'EMA_50', 'Upper_Band', 'Lower_Band', 'RSI',\n",
        "            'MACD', 'MACD_Signal', 'MACD_Histogram', 'ADX', '%K', '%D', 'ATR', 'VIX'\n",
        "        ]\n",
        "        X = df[features]\n",
        "        y = df['Target'].values.ravel()  # Converter y para array 1D\n",
        "\n",
        "        # Separar os √∫ltimos 10% dos dados para teste\n",
        "        test_size = int(0.1 * len(df))\n",
        "        X_train, X_test = X.iloc[:-test_size], X.iloc[-test_size:]\n",
        "        y_train, y_test = y[:-test_size], y[-test_size:]\n",
        "\n",
        "        # Verificar se h√° dados suficientes para treinamento e teste\n",
        "        if len(X_train) == 0 or len(X_test) == 0:\n",
        "            logging.error(f\"Erro: Dados insuficientes para treinamento/teste em {acao} no intervalo {intervalo}\")\n",
        "            return None, None\n",
        "\n",
        "        # Padronizar os dados\n",
        "        scaler = StandardScaler()\n",
        "        X_train_scaled = scaler.fit_transform(X_train)\n",
        "        X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "        # Ajuste de hiperpar√¢metros com GridSearchCV e TimeSeriesSplit\n",
        "        param_grid = {\n",
        "            'n_estimators': [50, 100, 200],\n",
        "            'max_depth': [None, 10, 20],\n",
        "            'min_samples_split': [2, 5, 10]\n",
        "        }\n",
        "        model = RandomForestRegressor(random_state=42)\n",
        "        tss = TimeSeriesSplit(n_splits=5)  # Usar 5 splits para valida√ß√£o cruzada\n",
        "        grid_search = GridSearchCV(model, param_grid, cv=tss, scoring='neg_mean_squared_error')\n",
        "        grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "        best_model = grid_search.best_estimator_\n",
        "\n",
        "        # Avaliar o modelo no conjunto de teste\n",
        "        y_pred = best_model.predict(X_test_scaled)\n",
        "        mse = mean_squared_error(y_test, y_pred)\n",
        "        mae = mean_absolute_error(y_test, y_pred)\n",
        "        logging.info(f\"Desempenho do modelo para {acao}: MSE = {mse:.2f}, MAE = {mae:.2f}\")\n",
        "\n",
        "        # Criar datas futuras\n",
        "        future_dates = [df.index[-1] + pd.Timedelta(days=i) for i in range(1, 6)]\n",
        "\n",
        "        # Criar features futuras com base em tend√™ncias\n",
        "        future_features = pd.DataFrame({\n",
        "            'SMA_9': [df['SMA_9'].iloc[-1]] * 5,\n",
        "            'SMA_21': [df['SMA_21'].iloc[-1]] * 5,\n",
        "            'EMA_50': [df['EMA_50'].iloc[-1]] * 5,\n",
        "            'Upper_Band': [df['Upper_Band'].iloc[-1]] * 5,\n",
        "            'Lower_Band': [df['Lower_Band'].iloc[-1]] * 5,\n",
        "            'RSI': [df['RSI'].iloc[-1]] * 5,\n",
        "            'MACD': [df['MACD'].iloc[-1]] * 5,\n",
        "            'MACD_Signal': [df['MACD_Signal'].iloc[-1]] * 5,\n",
        "            'MACD_Histogram': [df['MACD_Histogram'].iloc[-1]] * 5,\n",
        "            'ADX': [df['ADX'].iloc[-1]] * 5,\n",
        "            '%K': [df['%K'].iloc[-1]] * 5,\n",
        "            '%D': [df['%D'].iloc[-1]] * 5,\n",
        "            'ATR': [df['ATR'].iloc[-1]] * 5,\n",
        "            'VIX': [df['VIX'].iloc[-1]] * 5\n",
        "        }, index=future_dates)\n",
        "\n",
        "        # Transformar features futuras usando o scaler ajustado\n",
        "        future_features_scaled = scaler.transform(future_features)\n",
        "\n",
        "        # Fazer previs√µes\n",
        "        future_predictions = best_model.predict(future_features_scaled)\n",
        "\n",
        "        # Calcular volatilidade hist√≥rica (desvio padr√£o dos retornos di√°rios)\n",
        "        retornos = df['Close'].pct_change().dropna()\n",
        "        volatilidade = retornos.std() * np.sqrt(252)  # Volatilidade anualizada\n",
        "\n",
        "        # Calcular probabilidades para cada previs√£o\n",
        "        probabilidades = []\n",
        "        for i, previsao in enumerate(future_predictions):\n",
        "            dias = i + 1  # Horizonte de tempo em dias\n",
        "            probabilidade = calcular_probabilidade(df['Close'].iloc[-1], previsao, volatilidade, dias)\n",
        "            probabilidades.append((previsao, probabilidade, dias))\n",
        "\n",
        "        return future_predictions, probabilidades\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Erro ao prever pre√ßos para {acao}: {e}\", exc_info=True)\n",
        "        return None, None\n",
        "\n",
        "# Fun√ß√£o para gerar alertas de compra/venda com probabilidades\n",
        "def gerar_alertas(df, previsoes, probabilidades, acao, intervalo):\n",
        "    try:\n",
        "        # Garantir que last_price seja um valor escalar\n",
        "        last_price = df['Close'].iloc[-1]\n",
        "        if isinstance(last_price, pd.Series):\n",
        "            last_price = last_price.item()  # Converte para um valor escalar\n",
        "\n",
        "        if previsoes is not None and len(previsoes) > 0:\n",
        "            avg_future_price = np.mean(previsoes)\n",
        "\n",
        "            # Gerar alerta e justificativa\n",
        "            if avg_future_price > last_price * 1.02:  # Tend√™ncia de alta\n",
        "                alerta = 'üöÄ Compra sugerida'\n",
        "                justificativa = (\n",
        "                    f\"A m√©dia das previs√µes futuras ({avg_future_price:.2f}) √© 2% maior que o pre√ßo atual ({last_price:.2f}). \"\n",
        "                    f\"Isso indica uma tend√™ncia de alta.\"\n",
        "                )\n",
        "            elif avg_future_price < last_price * 0.98:  # Tend√™ncia de baixa\n",
        "                alerta = '‚ö†Ô∏è Venda sugerida'\n",
        "                justificativa = (\n",
        "                    f\"A m√©dia das previs√µes futuras ({avg_future_price:.2f}) √© 2% menor que o pre√ßo atual ({last_price:.2f}). \"\n",
        "                    f\"Isso indica uma tend√™ncia de baixa.\"\n",
        "                )\n",
        "            else:\n",
        "                alerta = 'üîç Acompanhar'\n",
        "                justificativa = (\n",
        "                    f\"A m√©dia das previs√µes futuras ({avg_future_price:.2f}) est√° dentro de 2% do pre√ßo atual ({last_price:.2f}). \"\n",
        "                    f\"Isso sugere que o mercado est√° est√°vel no momento.\"\n",
        "                )\n",
        "        else:\n",
        "            alerta = '‚ùå Sem previs√µes dispon√≠veis'\n",
        "            justificativa = 'N√£o h√° previs√µes dispon√≠veis para esta a√ß√£o.'\n",
        "\n",
        "        # Exibir resultados\n",
        "        print(f\"Stock: {acao} | Intervalo: {intervalo}\")\n",
        "        print(f\"Last price: {last_price:.2f}\")\n",
        "        print(f\"Predictions: {previsoes}\")\n",
        "        print(f\"Alert: {alerta}\")\n",
        "        print(f\"Justificativa: {justificativa}\")\n",
        "\n",
        "        # Exibir probabilidades\n",
        "        if probabilidades is not None:\n",
        "            print(\"\\nProbabilidades de Atingir o Pre√ßo Alvo:\")\n",
        "            for previsao, probabilidade, dias in probabilidades:\n",
        "                print(f\"Previs√£o: {previsao:.2f} | Probabilidade: {probabilidade * 100:.2f}% | Dias: {dias}\")\n",
        "\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Erro ao gerar alertas para {acao}: {e}\", exc_info=True)\n",
        "\n",
        "# Fun√ß√£o para obter o Top 10 da NASDAQ por capitaliza√ß√£o de mercado\n",
        "def obter_top_10_nasdaq():\n",
        "    \"\"\"\n",
        "    Obt√©m o Top 10 da NASDAQ por capitaliza√ß√£o de mercado.\n",
        "    \"\"\"\n",
        "    # Baixar a lista de tickers da NASDAQ\n",
        "    nasdaq_tickers = pd.read_html(\"https://en.wikipedia.org/wiki/Nasdaq-100\")[4]\n",
        "    top_10 = nasdaq_tickers.head(3)['Ticker'].tolist()\n",
        "    return top_10\n",
        "\n",
        "# Processar a√ß√µes\n",
        "acoes = obter_top_10_nasdaq()\n",
        "for acao in acoes:\n",
        "    df = baixar_dados(acao)\n",
        "    if df is not None:\n",
        "        previsoes, probabilidades = prever_precos_com_probabilidade(df, acao, \"1d\")\n",
        "        gerar_alertas(df, previsoes, probabilidades, acao, \"1d\")"
      ]
    }
  ]
}