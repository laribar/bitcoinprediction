{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOl3GuqcroAC8BNFZtIRYf2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laribar/bitcoinprediction/blob/main/Bot_Funcional.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ta\n",
        "!pip install yfinance\n",
        "!pip install xgboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9WNklK9o26s",
        "outputId": "2373e08b-c4b0-4b26-dc3b-b0caa053e795"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ta in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ta) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from ta) (2.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->ta) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->ta) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->ta) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->ta) (1.17.0)\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.11/dist-packages (0.2.55)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.0.2)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.32.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.3.7)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2025.1)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.11/dist-packages (from yfinance) (3.17.9)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.13.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (4.12.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (2025.1.31)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.14.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import ta\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "XGBClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=4,                 # menor profundidade = menos overfitting\n",
        "    subsample=0.8,               # usa 80% dos dados por √°rvore\n",
        "    colsample_bytree=0.8,        # usa 80% das features por √°rvore\n",
        "    learning_rate=0.05,          # suaviza o aprendizado\n",
        "    early_stopping_rounds=10,    # para de treinar se n√£o melhorar\n",
        "    eval_metric=\"mlogloss\",\n",
        "    use_label_encoder=False,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error"
      ],
      "metadata": {
        "id": "ceE5TfMwEtjv"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Configura√ß√µes\n",
        "ASSETS = ASSETS = [\"BTC-USD\", \"ETH-USD\", \"BNB-USD\", \"SOL-USD\", \"XRP-USD\",\n",
        "          \"AVAX-USD\", \"AAVE-USD\", \"DOT-USD\", \"NEAR-USD\", \"ADA-USD\"]\n",
        "\n",
        "TIMEFRAMES = [\n",
        "    {\"interval\": \"15m\", \"period\": \"30d\", \"atr\": 0.02},\n",
        "    {\"interval\": \"1h\", \"period\": \"90d\", \"atr\": 0.03},\n",
        "    {\"interval\": \"1d\", \"period\": \"1000d\", \"atr\": 0.05}\n",
        "]\n",
        "TELEGRAM_TOKEN = \"8044593190:AAFtUWYHd3uqd-AtQi3uqg42F9G6uV95v8k\"\n",
        "TELEGRAM_CHAT_ID = \"-4744645054\"\n",
        "\n",
        "# 2. Obten√ß√£o de dados\n",
        "\n",
        "def get_stock_data(asset, interval=\"15m\", period=\"700d\"):\n",
        "    data = yf.download(asset, period=period, interval=interval, progress=False, auto_adjust=False)\n",
        "    if isinstance(data.columns, pd.MultiIndex):\n",
        "        data.columns = data.columns.get_level_values(0)\n",
        "    data.columns = [col.split()[-1] if \" \" in col else col for col in data.columns]\n",
        "    # Remove colunas duplicadas ou com sufixos como 'Adj Close'\n",
        "    data = data.loc[:, ~data.columns.duplicated()]\n",
        "    col_map = {}\n",
        "    for col in data.columns:\n",
        "        for std_col in [\"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\"]:\n",
        "            if std_col.lower() in col.lower():\n",
        "                col_map[col] = std_col\n",
        "    data = data.rename(columns=col_map)\n",
        "    # Garante que apenas as colunas necess√°rias estejam presentes\n",
        "    data = data[[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]]\n",
        "    required = [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
        "    if not all(col in data.columns for col in required):\n",
        "        raise ValueError(f\"‚ö†Ô∏è Dados de {asset} n√£o possuem todas as colunas necess√°rias.\")\n",
        "    return data\n",
        "\n",
        "# 3. Indicadores\n",
        "\n",
        "def calculate_indicators(data):\n",
        "    data = data.copy()\n",
        "    data.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    for col in [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]:\n",
        "        if isinstance(data[col], pd.DataFrame):\n",
        "            data[col] = data[col].iloc[:, 0]\n",
        "        elif isinstance(data[col].iloc[0], (list, np.ndarray)):\n",
        "            data[col] = data[col].apply(lambda x: x[0] if isinstance(x, (list, np.ndarray)) else x)\n",
        "        data[col] = data[col].astype(float)\n",
        "\n",
        "    # Indicadores\n",
        "    data[\"RSI\"] = ta.momentum.RSIIndicator(close=data[\"Close\"], window=14).rsi()\n",
        "    data[\"SMA_50\"] = ta.trend.SMAIndicator(close=data[\"Close\"], window=50).sma_indicator()\n",
        "    data[\"SMA_200\"] = ta.trend.SMAIndicator(close=data[\"Close\"], window=200).sma_indicator()\n",
        "\n",
        "    macd = ta.trend.MACD(close=data[\"Close\"])\n",
        "    data[\"MACD\"] = macd.macd()\n",
        "    data[\"MACD_Signal\"] = macd.macd_signal()\n",
        "\n",
        "    bb = ta.volatility.BollingerBands(close=data[\"Close\"], window=20)\n",
        "    data[\"Bollinger_Upper\"] = bb.bollinger_hband()\n",
        "    data[\"Bollinger_Lower\"] = bb.bollinger_lband()\n",
        "\n",
        "    adx = ta.trend.ADXIndicator(high=data[\"High\"], low=data[\"Low\"], close=data[\"Close\"], window=14)\n",
        "    data[\"ADX\"] = adx.adx()\n",
        "\n",
        "    stoch = ta.momentum.StochasticOscillator(high=data[\"High\"], low=data[\"Low\"], close=data[\"Close\"], window=14)\n",
        "    data[\"Stoch_K\"] = stoch.stoch()\n",
        "    data[\"Stoch_D\"] = stoch.stoch_signal()\n",
        "\n",
        "    data[\"TP\"] = (data[\"High\"] + data[\"Low\"] + data[\"Close\"]) / 3\n",
        "    data[\"VWAP\"] = (data[\"TP\"] * data[\"Volume\"]).cumsum() / (data[\"Volume\"].replace(0, np.nan).cumsum())\n",
        "    data.drop(\"TP\", axis=1, inplace=True)\n",
        "\n",
        "    data[\"Doji\"] = ((abs(data[\"Close\"] - data[\"Open\"]) / (data[\"High\"] - data[\"Low\"] + 1e-9)) < 0.1).astype(int)\n",
        "    data[\"Engulfing\"] = ((data[\"Open\"].shift(1) > data[\"Close\"].shift(1)) & (data[\"Open\"] < data[\"Close\"]) &\n",
        "                          (data[\"Close\"] > data[\"Open\"].shift(1)) & (data[\"Open\"] < data[\"Close\"].shift(1))).astype(int)\n",
        "    data[\"Hammer\"] = (((data[\"High\"] - data[\"Low\"]) > 3 * abs(data[\"Open\"] - data[\"Close\"])) &\n",
        "                       ((data[\"Close\"] - data[\"Low\"]) / (data[\"High\"] - data[\"Low\"] + 1e-9) > 0.6) &\n",
        "                       ((data[\"Open\"] - data[\"Low\"]) / (data[\"High\"] - data[\"Low\"] + 1e-9) > 0.6)).astype(int)\n",
        "\n",
        "    data.dropna(inplace=True)\n",
        "    return data\n",
        "\n",
        "\n",
        "\n",
        "# 4. Modelo\n",
        "\n",
        "# Substitui√ß√£o da fun√ß√£o train_ml_model para usar XGBoost no lugar de RandomForestClassifier\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "def train_ml_model(data, verbose=False):\n",
        "    if len(data) < 100:\n",
        "        return None\n",
        "\n",
        "    df = data.copy()\n",
        "\n",
        "    # Adiciona previs√£o do LSTM como feature (stacking)\n",
        "    try:\n",
        "        lstm_model = train_lstm_model(df)\n",
        "        lstm_preds = []\n",
        "        for i in range(len(df)):\n",
        "            sub_df = df.iloc[:i+1]\n",
        "            if len(sub_df) < 20:\n",
        "                lstm_preds.append(np.nan)\n",
        "            else:\n",
        "                pred = predict_with_lstm(lstm_model, sub_df)\n",
        "                lstm_preds.append(pred)\n",
        "        df[\"LSTM_PRED\"] = lstm_preds\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Erro ao gerar LSTM_PRED: {e}\")\n",
        "        df[\"LSTM_PRED\"] = np.nan\n",
        "\n",
        "    # Sinal com base em retorno futuro\n",
        "    df[\"Future_Close\"] = df[\"Close\"].shift(-5)\n",
        "    df[\"Future_Return\"] = df[\"Future_Close\"] / df[\"Close\"] - 1\n",
        "    df[\"Signal\"] = np.select([\n",
        "        df[\"Future_Return\"] > 0.015,\n",
        "        df[\"Future_Return\"] < -0.015\n",
        "    ], [1, -1], default=0)\n",
        "\n",
        "    features = get_feature_columns()\n",
        "    df.dropna(inplace=True)\n",
        "    X = df[features]\n",
        "    y = df[\"Signal\"].map({-1: 0, 0: 1, 1: 2})  # Re-mapeamento para o XGBoost\n",
        "\n",
        "    signal_count = (y == 1).sum()\n",
        "    if verbose:\n",
        "        print(f\"üìâ Sinais de COMPRA encontrados: {signal_count} em {len(y)} candles\")\n",
        "\n",
        "    if len(np.unique(y)) < 2:\n",
        "        return None\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
        "    if len(np.unique(y_train)) < 2:\n",
        "        return None\n",
        "\n",
        "    model = XGBClassifier(\n",
        "        n_estimators=200,\n",
        "        max_depth=6,\n",
        "        learning_rate=0.1,\n",
        "        use_label_encoder=False,\n",
        "        eval_metric=\"mlogloss\",\n",
        "        random_state=42\n",
        "    )\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = model.predict(X_val)\n",
        "    report = classification_report(y_val, y_pred, output_dict=True, zero_division=0)\n",
        "\n",
        "    model.validation_score = {\n",
        "        \"accuracy\": report.get(\"accuracy\"),\n",
        "        \"precision\": report.get(\"1\", {}).get(\"precision\"),\n",
        "        \"recall\": report.get(\"1\", {}).get(\"recall\"),\n",
        "        \"f1\": report.get(\"1\", {}).get(\"f1-score\")\n",
        "    }\n",
        "\n",
        "    feature_importances = dict(zip(features, model.feature_importances_))\n",
        "    sorted_feat = sorted(feature_importances.items(), key=lambda x: x[1], reverse=True)\n",
        "    print(\"\\nüìä Import√¢ncia das features (XGBoost):\")\n",
        "    for feat, score in sorted_feat[:5]:\n",
        "        print(f\"   {feat}: {score:.4f}\")\n",
        "\n",
        "    data[\"LSTM_PRED\"] = df[\"LSTM_PRED\"]  # Garante acesso √† coluna no run_analysis\n",
        "    return model\n",
        "\n",
        "    # 4.1 MODELO LSTM\n",
        "def prepare_lstm_data(data, feature_col=\"Close\", window_size=20):\n",
        "    df = data.copy().reset_index(drop=True)\n",
        "    values = df[feature_col].values.reshape(-1, 1)\n",
        "    scaler = MinMaxScaler()\n",
        "    scaled = scaler.fit_transform(values)\n",
        "\n",
        "    X, y = [], []\n",
        "    for i in range(window_size, len(scaled)):\n",
        "        X.append(scaled[i - window_size:i, 0])\n",
        "        y.append(scaled[i, 0])\n",
        "\n",
        "    X, y = np.array(X), np.array(y)\n",
        "    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
        "    return X, y, scaler\n",
        "\n",
        "# Novo: treina o modelo LSTM\n",
        "\n",
        "def train_lstm_model(data, window_size=20, verbose=False):\n",
        "    if len(data) < window_size + 20:\n",
        "        return None\n",
        "\n",
        "    X, y, scaler = prepare_lstm_data(data, window_size=window_size)\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units=50, return_sequences=True, input_shape=(X.shape[1], 1)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(LSTM(units=50))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "    model.fit(X, y, epochs=10, batch_size=32, verbose=0 if not verbose else 1)\n",
        "\n",
        "    model.scaler = scaler\n",
        "    model.window_size = window_size\n",
        "    return model\n",
        "\n",
        "# Novo: previs√£o com LSTM\n",
        "\n",
        "def predict_with_lstm(model, data):\n",
        "    df = data.copy().reset_index(drop=True)\n",
        "    values = df[\"Close\"].values.reshape(-1, 1)\n",
        "    scaled = model.scaler.transform(values)\n",
        "\n",
        "    last_sequence = scaled[-model.window_size:]\n",
        "    X_pred = np.reshape(last_sequence, (1, model.window_size, 1))\n",
        "    predicted_scaled = model.predict(X_pred)[0][0]\n",
        "    predicted_price = model.scaler.inverse_transform([[predicted_scaled]])[0][0]\n",
        "    return round(predicted_price, 2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 5. Utilit√°rios\n",
        "\n",
        "def get_feature_columns():\n",
        "    return [\n",
        "        \"RSI\", \"MACD\", \"MACD_Signal\", \"SMA_50\", \"SMA_200\", \"Bollinger_Upper\",\n",
        "        \"Bollinger_Lower\", \"ADX\", \"Stoch_K\", \"Stoch_D\", \"VWAP\",\n",
        "        \"Doji\", \"Engulfing\", \"Hammer\", \"LSTM_PRED\"\n",
        "    ]\n",
        "\n",
        "def generate_explanation(row, prediction):\n",
        "    explanation = []\n",
        "    if prediction == 1:\n",
        "        explanation.append(\"üü¢ O modelo prev√™ uma tend√™ncia de ALTA.\")\n",
        "    elif prediction == -1:\n",
        "        explanation.append(\"üî¥ O modelo prev√™ uma tend√™ncia de BAIXA.\")\n",
        "    else:\n",
        "        explanation.append(\"‚ö™ Sinal neutro.\")\n",
        "\n",
        "    if row[\"RSI\"] < 30:\n",
        "        explanation.append(\"üîΩ RSI abaixo de 30 indica sobrevenda.\")\n",
        "    elif row[\"RSI\"] > 70:\n",
        "        explanation.append(\"üîº RSI acima de 70 indica sobrecompra.\")\n",
        "\n",
        "    if row[\"SMA_50\"] > row[\"SMA_200\"]:\n",
        "        explanation.append(\"üìà SMA 50 acima da 200, tend√™ncia de alta.\")\n",
        "    else:\n",
        "        explanation.append(\"üìâ SMA 50 abaixo da 200, tend√™ncia de baixa.\")\n",
        "\n",
        "    if row[\"MACD\"] > row[\"MACD_Signal\"]:\n",
        "        explanation.append(\"üíπ MACD cruzando para cima, poss√≠vel revers√£o positiva.\")\n",
        "    else:\n",
        "        explanation.append(\"üîª MACD abaixo da linha de sinal.\")\n",
        "\n",
        "    if row[\"Doji\"] == 1:\n",
        "        explanation.append(\"‚ö†Ô∏è Padr√£o de candle Doji detectado (poss√≠vel revers√£o).\")\n",
        "\n",
        "    if row[\"Engulfing\"] == 1:\n",
        "        explanation.append(\"üìä Padr√£o de engolfo detectado (sinal forte de revers√£o).\")\n",
        "\n",
        "    return \"\\n\".join(explanation)\n",
        "\n",
        "def calculate_targets(current_price, direction, atr=0.02):\n",
        "    if direction == 1:\n",
        "        return {\n",
        "            \"TP1\": round(current_price * (1 + atr * 0.5), 2),\n",
        "            \"TP2\": round(current_price * (1 + atr * 1.0), 2),\n",
        "            \"SL\": round(current_price * (1 - atr * 0.5), 2)\n",
        "        }\n",
        "    elif direction == -1:\n",
        "        return {\n",
        "            \"TP1\": round(current_price * (1 - atr * 0.5), 2),\n",
        "            \"TP2\": round(current_price * (1 - atr * 1.0), 2),\n",
        "            \"SL\": round(current_price * (1 + atr * 0.5), 2)\n",
        "        }\n",
        "    else:\n",
        "        return {\"TP1\": None, \"TP2\": None, \"SL\": None}\n",
        "\n",
        "\n",
        "def send_telegram_message(message):\n",
        "    url = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage\"\n",
        "    payload = {\"chat_id\": TELEGRAM_CHAT_ID, \"text\": message, \"parse_mode\": \"HTML\"}\n",
        "    response = requests.post(url, json=payload)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        print(\"üì® Mensagem enviada com sucesso!\")\n",
        "    else:\n",
        "        print(f\"‚ùå Erro ao enviar mensagem: {response.status_code} - {response.text}\")\n",
        "\n",
        "\n",
        "\n",
        "def predict_next_closes(data, n_steps=5):\n",
        "  from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "  df = data.copy().reset_index(drop=True)\n",
        "  features = get_feature_columns()\n",
        "  df.dropna(inplace=True)\n",
        "\n",
        "  X = df[features]\n",
        "  y = df[\"Close\"].shift(-1).dropna()\n",
        "  X = X.loc[y.index]\n",
        "\n",
        "  if len(X) < 100:\n",
        "      return [None] * n_steps\n",
        "\n",
        "  model = RandomForestRegressor(n_estimators=200, max_depth=8, random_state=42)\n",
        "  model.fit(X, y)\n",
        "\n",
        "  last_row = df[features].iloc[-1].copy()\n",
        "  preds = []\n",
        "\n",
        "  for step in range(n_steps):\n",
        "      X_input = pd.DataFrame([last_row], columns=features)\n",
        "      next_close = model.predict(X_input)[0]\n",
        "      preds.append(round(next_close, 2))\n",
        "\n",
        "      # Simula avan√ßo do mercado\n",
        "      last_row[\"Close\"] = next_close\n",
        "      if \"SMA_50\" in last_row:\n",
        "          last_row[\"SMA_50\"] = last_row[\"SMA_50\"] * 0.9 + next_close * 0.1\n",
        "      if \"SMA_200\" in last_row:\n",
        "          last_row[\"SMA_200\"] = last_row[\"SMA_200\"] * 0.95 + next_close * 0.05\n",
        "      if \"VWAP\" in last_row:\n",
        "          last_row[\"VWAP\"] = last_row[\"VWAP\"] * 0.95 + next_close * 0.05\n",
        "      if \"RSI\" in last_row:\n",
        "          last_row[\"RSI\"] = min(100, max(0, last_row[\"RSI\"] + np.random.normal(0, 0.5)))\n",
        "      if \"MACD\" in last_row:\n",
        "          last_row[\"MACD\"] += np.random.normal(0, 0.3)\n",
        "      if \"MACD_Signal\" in last_row:\n",
        "          last_row[\"MACD_Signal\"] += np.random.normal(0, 0.2)\n",
        "\n",
        "      last_row = last_row[features]\n",
        "\n",
        "  return preds\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 6. Execu√ß√£o\n",
        "\n",
        "def run_analysis(\n",
        "    selected_timeframes=None,\n",
        "    plot_timeframes=[\"15m\", \"1h\"],\n",
        "    alert_timeframes=[\"15m\", \"1h\", \"1d\"]\n",
        "):\n",
        "    if selected_timeframes is None:\n",
        "        selected_timeframes = TIMEFRAMES\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for asset in ASSETS:\n",
        "        print(f\"\\nüìä Analisando {asset}...\")\n",
        "        models = {}\n",
        "        lstm_models = {}\n",
        "        data = {}\n",
        "\n",
        "        try:\n",
        "            for tf in selected_timeframes:\n",
        "                interval = tf['interval']\n",
        "                period = tf['period']\n",
        "                data[interval] = calculate_indicators(get_stock_data(asset, interval, period))\n",
        "                models[interval] = train_ml_model(data[interval], verbose=True)\n",
        "                lstm_models[interval] = train_lstm_model(data[interval])\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erro ao processar {asset}: {e}\")\n",
        "            continue\n",
        "\n",
        "        if all(model is None for model in models.values()):\n",
        "            print(f\"‚ö†Ô∏è Nenhum modelo foi treinado para {asset}.\")\n",
        "            continue\n",
        "\n",
        "        current_price = data.get(\"15m\", data[list(data.keys())[0]])[\"Close\"].iloc[-1]\n",
        "        message = f\"üîç {asset}\\nüí∞ Pre√ßo atual: ${current_price:.2f}\\n\"\n",
        "\n",
        "        for tf in selected_timeframes:\n",
        "            interval = tf['interval']\n",
        "            model = models.get(interval)\n",
        "\n",
        "            if model is None:\n",
        "                message += f\"\\n‚è±Ô∏è {interval}: Dados insuficientes para este timeframe.\\n\"\n",
        "                continue\n",
        "\n",
        "            latest_data = data[interval].iloc[-1]\n",
        "            features = get_feature_columns()\n",
        "            input_data = pd.DataFrame([latest_data[features]])\n",
        "            prediction = model.predict(input_data)[0]\n",
        "            proba = model.predict_proba(input_data)[0][np.where(model.classes_ == prediction)[0][0]]\n",
        "\n",
        "            def safe_format(val): return f\"{val:.2f}\" if val is not None else \"N/A\"\n",
        "            score = model.validation_score\n",
        "            score_text = f\"üìà Accuracy: {safe_format(score['accuracy'])} | Precision: {safe_format(score['precision'])} | Recall: {safe_format(score['recall'])}\"\n",
        "\n",
        "            targets = calculate_targets(current_price, prediction, tf['atr'])\n",
        "            explanation = generate_explanation(latest_data, prediction)\n",
        "\n",
        "            # Novo: Previs√£o com LSTM\n",
        "            predicted_price_lstm = None\n",
        "            if lstm_models.get(interval):\n",
        "                try:\n",
        "                    predicted_price_lstm = predict_with_lstm(lstm_models[interval], data[interval])\n",
        "                except Exception as e:\n",
        "                    print(f\"[!] Erro na previs√£o LSTM: {e}\")\n",
        "\n",
        "            time_label = {\"15m\": \"15 minutos\", \"1h\": \"1 hora\", \"1d\": \"Di√°rio\"}[interval]\n",
        "\n",
        "            message += f\"\"\"\n",
        "‚è±Ô∏è {time_label}:\n",
        "{'üü¢ COMPRA' if prediction == 1 else ('üî¥ VENDA' if prediction == -1 else '‚ö™ NEUTRO')} com {proba*100:.1f}% de confian√ßa\n",
        "üéØ TP1: ${targets['TP1']} | TP2: ${targets['TP2']} | SL: ${targets['SL']}\n",
        "üìå Previs√£o: ${current_price * (1 + (tf['atr'] if prediction == 1 else (-tf['atr'] if prediction == -1 else 0))):.2f}\n",
        "{score_text}\n",
        "{explanation}\n",
        "üîÆ Pre√ßo previsto (LSTM): ${predicted_price_lstm if predicted_price_lstm else 'N/A'}\n",
        "\"\"\"\n",
        "\n",
        "            result = {\n",
        "                \"Asset\": asset,\n",
        "                \"Timeframe\": interval,\n",
        "                \"Date\": latest_data.name,\n",
        "                \"Price\": current_price,\n",
        "                \"Signal\": prediction,\n",
        "                \"Confidence\": round(proba, 4),\n",
        "                \"TP1\": targets['TP1'],\n",
        "                \"TP2\": targets['TP2'],\n",
        "                \"SL\": targets['SL'],\n",
        "                \"Accuracy\": score['accuracy'],\n",
        "                \"Precision\": score['precision'],\n",
        "                \"Recall\": score['recall'],\n",
        "                \"F1\": score['f1'],\n",
        "                \"LSTM_Predicted\": predicted_price_lstm\n",
        "            }\n",
        "\n",
        "            results.append(result)\n",
        "\n",
        "            print(f\"\\nüîé Verificando envio de alerta para {asset} | timeframe: {interval}\")\n",
        "            print(f\"‚û°Ô∏è Confian√ßa: {proba:.2f} | Alerta permitido? {interval in alert_timeframes}\")\n",
        "            print(f\"‚û°Ô∏è Explica√ß√£o:\\n{explanation}\")\n",
        "\n",
        "            if interval in alert_timeframes:\n",
        "                if proba > 0.60:\n",
        "                    print(\"‚úÖ Crit√©rio de confian√ßa atendido (proba > 0.60)\")\n",
        "                if \"MACD\" in explanation and \"SMA 50 acima\" in explanation:\n",
        "                    print(\"‚úÖ Crit√©rio t√©cnico atendido (MACD + SMA 50)\")\n",
        "\n",
        "                if proba > 0.60 or (\"MACD\" in explanation and \"SMA 50 acima\" in explanation):\n",
        "                    send_telegram_message(message)\n",
        "                    print(\"üì® Mensagem enviada para o Telegram!\")\n",
        "                else:\n",
        "                    print(\"‚õî Alerta n√£o enviado: confian√ßa ou crit√©rio t√©cnico insuficiente.\")\n",
        "            else:\n",
        "                print(\"‚õî Timeframe n√£o permitido para alerta.\")\n",
        "\n",
        "            if interval in plot_timeframes:\n",
        "                try:\n",
        "                    df = data[interval].copy().tail(50)\n",
        "                    freq_map = {\"15m\": \"15min\", \"1h\": \"h\", \"1d\": \"D\"}\n",
        "                    freq = freq_map.get(interval, \"1min\")\n",
        "                    df[\"Datetime\"] = (\n",
        "                        df.index if isinstance(df.index, pd.DatetimeIndex)\n",
        "                        else pd.date_range(end=pd.Timestamp.now(), periods=len(df), freq=freq)\n",
        "                    )\n",
        "                    plt.figure(figsize=(10, 4))\n",
        "                    plt.plot(df[\"Datetime\"], df[\"Close\"], label=\"Pre√ßo\")\n",
        "                    if targets[\"TP1\"]:\n",
        "                        plt.axhline(targets['TP1'], color='green', linestyle='--', label='TP1')\n",
        "                        plt.axhline(targets['TP2'], color='green', linestyle=':')\n",
        "                        plt.axhline(targets['SL'], color='red', linestyle='--', label='SL')\n",
        "                    plt.title(f\"{asset} - {interval.upper()} - Previs√£o: {'COMPRA' if prediction == 1 else 'VENDA' if prediction == -1 else 'NEUTRO'}\")\n",
        "                    plt.legend()\n",
        "                    plt.xticks(rotation=45)\n",
        "                    plt.tight_layout()\n",
        "                    plt.grid()\n",
        "                    plt.show()\n",
        "                except Exception as e:\n",
        "                    print(f\"[!] Falha ao gerar gr√°fico: {e}\")\n",
        "\n",
        "    df_results = pd.DataFrame(results)\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "    filename = f\"model_results_{timestamp}.csv\"\n",
        "    df_results.to_csv(filename, index=False)\n",
        "    print(f\"\\nüìÅ Resultados salvos em: {filename}\")\n",
        "\n",
        "    win_trades = df_results[(df_results['Signal'] == 1) & (df_results['Confidence'] > 0.6)]\n",
        "    if not win_trades.empty:\n",
        "        avg_target = (win_trades['TP1'] - win_trades['Price']).mean()\n",
        "        print(f\"\\n‚úÖ Backtest TP1 m√©dio: +${avg_target:.2f} por trade em sinais de compra com confian√ßa > 60%\")\n",
        "    else:\n",
        "        print(\"\\n‚ö†Ô∏è Nenhum trade de compra acima de 60% de confian√ßa para backtest.\")\n",
        "\n",
        "\n",
        "# Execu√ß√£o em loop (a cada 1 hora)\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "def is_time_to_run(interval):\n",
        "    now = datetime.now()\n",
        "    if interval == \"15m\":\n",
        "        return now.minute % 15 == 0\n",
        "    elif interval == \"1h\":\n",
        "        return now.minute == 0\n",
        "    elif interval == \"1d\":\n",
        "        return now.hour == 8 and now.minute == 0\n",
        "    return False\n",
        "\n",
        "while True:\n",
        "    now = datetime.now()\n",
        "    print(f\"\\n‚è∞ Verificando timeframes - {now.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "\n",
        "    for tf in TIMEFRAMES:\n",
        "        interval = tf[\"interval\"]\n",
        "        if is_time_to_run(interval):\n",
        "            print(f\"\\nüöÄ Rodando an√°lise para timeframe {interval}...\")\n",
        "\n",
        "            try:\n",
        "                run_analysis(\n",
        "                    selected_timeframes=[tf],\n",
        "                    plot_timeframes=[\"1d\"],        # Mude aqui se quiser ver gr√°fico de outros timeframes\n",
        "                    alert_timeframes=[\"15m\", \"1h\", \"1d\"]\n",
        "\n",
        "                )\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Erro durante a an√°lise de {interval}: {e}\")\n",
        "        else:\n",
        "            print(f\"‚è≥ Ainda n√£o √© hora para {interval}...\")\n",
        "\n",
        "    time.sleep(60)  # Verifica a cada 1 minuto\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDxRXv4aJLK0",
        "outputId": "d5354e72-699e-4453-cc4b-f54af7ef7b6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚è∞ Verificando timeframes - 2025-03-27 19:56:01\n",
            "‚è≥ Ainda n√£o √© hora para 15m...\n",
            "‚è≥ Ainda n√£o √© hora para 1h...\n",
            "‚è≥ Ainda n√£o √© hora para 1d...\n"
          ]
        }
      ]
    }
  ]
}